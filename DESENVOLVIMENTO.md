# Guia de Desenvolvimento AnythingLLM

Este guia fornece um workflow completo para desenvolvimento local e deploy no Digital Ocean com mÃ­nimo atrito.

## ğŸš€ InÃ­cio RÃ¡pido

### 1. ConfiguraÃ§Ã£o Inicial (Uma vez)

```bash
# Clone e configure o projeto
git clone <your-repo>
cd gpt_jholy

# Setup automÃ¡tico (dependÃªncias + banco + ENVs)
yarn setup
yarn prisma:setup
```

### 2. Desenvolvimento DiÃ¡rio

#### OpÃ§Ã£o A: Desenvolvimento Nativo (Recomendado)
```bash
# Terminal 1: Server
yarn dev:server

# Terminal 2: Frontend (http://localhost:3000)
yarn dev:frontend

# Terminal 3: Collector
yarn dev:collector
```

#### OpÃ§Ã£o B: Desenvolvimento com Docker
```bash
# Usar configuraÃ§Ã£o otimizada
docker-compose -f docker-compose.dev.yml up -d

# Com PostgreSQL e Ollama
docker-compose -f docker-compose.dev.yml --profile postgres --profile ollama up -d
```

## ğŸ›  ConfiguraÃ§Ãµes por Ambiente

### Desenvolvimento Local
- **Arquivo**: `server/.env.local`
- **LLM**: Ollama (gratuito) - `llama3.2:1b`
- **Embedding**: Nativo (gratuito)
- **Vector DB**: LanceDB (local)
- **Banco**: SQLite (padrÃ£o)

### Testes de ProduÃ§Ã£o Local
- **Arquivo**: `docker/.env.production`
- **LLM**: OpenAI (configurar API key)
- **Vector DB**: PostgreSQL + pgvector
- **Banco**: PostgreSQL

### ProduÃ§Ã£o Digital Ocean
- **Arquivo**: `docker/.env.production`
- **LLM**: OpenAI/Anthropic (melhor qualidade)
- **Infraestrutura**: Terraform automatizado

## ğŸ“ Estrutura de Arquivos de ConfiguraÃ§Ã£o

```
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ .env.development     # Ambiente padrÃ£o
â”‚   â””â”€â”€ .env.local          # Desenvolvimento com Ollama (criado)
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ .env                # Frontend (jÃ¡ configurado)
â”œâ”€â”€ collector/
â”‚   â””â”€â”€ .env                # Collector (jÃ¡ configurado)
â””â”€â”€ docker/
    â”œâ”€â”€ .env                # Docker desenvolvimento
    â””â”€â”€ .env.production     # ProduÃ§Ã£o/staging (criado)
```

## ğŸ³ Docker Workflows

### Desenvolvimento Local
```bash
# Build e teste local
docker-compose -f docker-compose.dev.yml up --build

# Com serviÃ§os opcionais
docker-compose -f docker-compose.dev.yml --profile postgres up -d
```

### Teste de ProduÃ§Ã£o Local
```bash
# Simular ambiente de produÃ§Ã£o
docker-compose -f docker-compose.production.yml --profile production up -d

# Com reverse proxy
docker-compose -f docker-compose.production.yml --profile production --profile nginx up -d
```

## â˜ï¸ Deploy Digital Ocean

### Setup Inicial
```bash
cd cloud-deployments/digitalocean/terraform/

# 1. Configurar credenciais
cp terraform.tfvars.example terraform.tfvars
# Editar terraform.tfvars com seu token e configuraÃ§Ãµes

# 2. Configurar arquivo de produÃ§Ã£o
cp ../../../docker/.env.production .env.production
# Editar .env.production com suas API keys

# 3. Deploy
terraform init
terraform plan
terraform apply
```

### ConfiguraÃ§Ã£o do .env.production
Antes do deploy, configure:
```bash
# SeguranÃ§a (OBRIGATÃ“RIO)
SIG_KEY='gere-string-aleatoria-32-chars'
SIG_SALT='gere-string-aleatoria-32-chars'
JWT_SECRET='gere-string-aleatoria-12-chars'
AUTH_TOKEN='senha-forte-para-acesso'

# APIs (Configure suas chaves)
OPEN_AI_KEY=sk-sua-chave-openai
```

### Monitoramento pÃ³s-deploy
```bash
# SSH no servidor
ssh root@IP_DO_SERVIDOR

# Verificar logs
sudo tail -f /var/log/cloud-init-output.log

# Status do container
docker ps

# Logs da aplicaÃ§Ã£o
docker logs anythingllm
```

## ğŸ”„ Workflows Comuns

### Testar Localmente Antes do Deploy
```bash
# 1. Desenvolvimento nativo
yarn dev:server & yarn dev:frontend & yarn dev:collector

# 2. Teste Docker local
docker-compose -f docker-compose.production.yml --profile production up

# 3. Deploy quando satisfeito
cd cloud-deployments/digitalocean/terraform/ && terraform apply
```

### Atualizar ProduÃ§Ã£o
```bash
# 1. Fazer mudanÃ§as locais
# 2. Testar localmente
# 3. Commit e push
# 4. SSH no servidor e atualizar:

ssh root@IP_DO_SERVIDOR
docker pull mintplexlabs/anythingllm:latest
docker stop anythingllm && docker rm anythingllm
/usr/local/bin/start-anythingllm.sh
```

### Backup e Restore
```bash
# Backup (local)
docker exec anythingllm tar czf - /app/server/storage | gzip > backup.tar.gz

# Restore (local)
gunzip -c backup.tar.gz | docker exec -i anythingllm tar xzf - -C /
```

## ğŸ§ª Testing

### Testes UnitÃ¡rios
```bash
# Executar todos os testes
yarn test

# Teste especÃ­fico
yarn test --testNamePattern="nome-do-teste"
```

### Testes de IntegraÃ§Ã£o
```bash
# Testar API endpoints
curl http://localhost:3001/api/ping
curl http://localhost:3001/api/system/system-vectors

# Testar upload de documento
curl -X POST http://localhost:3001/api/document/upload \
  -F "file=@documento.pdf"
```

## ğŸ›¡ SeguranÃ§a

### Desenvolvimento
- âœ… Usar configuraÃ§Ãµes simples
- âœ… Telemetria desabilitada
- âœ… Senhas simples para facilitar

### ProduÃ§Ã£o
- âš ï¸ Alterar todas as chaves de seguranÃ§a
- âš ï¸ Configurar AUTH_TOKEN forte
- âš ï¸ Usar HTTPS em produÃ§Ã£o
- âš ï¸ Backup regular dos dados

## ğŸ› Troubleshooting

### Container nÃ£o inicia
```bash
# Verificar logs
docker logs anythingllm

# Verificar configuraÃ§Ã£o
docker exec anythingllm cat /app/server/.env

# Recriar container
docker stop anythingllm && docker rm anythingllm
/usr/local/bin/start-anythingllm.sh
```

### Erro de conexÃ£o LLM
```bash
# Testar Ollama local
curl http://localhost:11434/api/version

# Testar OpenAI
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### Banco de dados corrompido
```bash
# Reset desenvolvimento
yarn prisma:reset

# ProduÃ§Ã£o (cuidado!)
docker exec anythingllm npx prisma migrate reset --force
```

## ğŸ“Š Custos Estimados

### Desenvolvimento
- **Local**: Gratuito (Ollama + SQLite)
- **APIs**: $0/mÃªs (usando modelos locais)

### ProduÃ§Ã£o Digital Ocean
- **Droplet s-2vcpu-2gb**: $12/mÃªs
- **Volume 20GB**: $2/mÃªs
- **OpenAI API**: $5-20/mÃªs (dependendo do uso)
- **Total**: ~$20-35/mÃªs

## ğŸ”— Links Ãšteis

- [DocumentaÃ§Ã£o AnythingLLM](https://docs.anythingllm.com/)
- [Digital Ocean Terraform](https://registry.terraform.io/providers/digitalocean/digitalocean/latest/docs)
- [Ollama Models](https://ollama.ai/library)
- [OpenAI Pricing](https://openai.com/pricing)

## ğŸ“ Notas de Desenvolvimento

### LLM Providers Recomendados
1. **Desenvolvimento**: Ollama (gratuito, local)
2. **ProduÃ§Ã£o**: OpenAI GPT-4o (melhor qualidade)
3. **EconÃ´mico**: Groq (rÃ¡pido e barato)

### Vector Databases
1. **Desenvolvimento**: LanceDB (local, simples)
2. **ProduÃ§Ã£o**: PostgreSQL + pgvector (robusto)
3. **Scale**: Pinecone (managed, caro)

### EstratÃ©gia de Backup
- **Desenvolvimento**: Git + exports manuais
- **ProduÃ§Ã£o**: Automated backups + volume snapshots