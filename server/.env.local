# AnythingLLM - Configura√ß√£o Enxuta para Desenvolvimento
# Setup r√°pido com APIs online - zero overhead local

SERVER_PORT=3001
JWT_SECRET="dev-jwt-secret-change-in-production-1234567890abcdef"
JWT_EXPIRY="30d"
SIG_KEY='dev-sig-key-change-in-production-32chars'
SIG_SALT='dev-sig-salt-change-in-production-32'

###########################################
######## LLM PROVIDER - OPENAI ###########
###########################################
# OpenAI para desenvolvimento (r√°pido, sem overhead local)
LLM_PROVIDER='openai'
OPEN_AI_KEY=sk-your-openai-api-key-here
OPEN_MODEL_PREF='gpt-4o-mini'  # Modelo econ√¥mico para desenvolvimento
# OPEN_MODEL_PREF='gpt-3.5-turbo'  # Alternativa ainda mais barata

###########################################
######## EMBEDDING - NATIVO ##############
###########################################
# Embedding nativo (sem APIs extras, mais econ√¥mico)
EMBEDDING_ENGINE='native'
EMBEDDING_MODEL_PREF='Xenova/all-MiniLM-L6-v2'

###########################################
######## VECTOR DATABASE - LANCEDB #######
###########################################
# LanceDB local (zero configura√ß√£o, r√°pido)
VECTOR_DB="lancedb"

###########################################
######## AUDIO MODELS ####################
###########################################
# Local para desenvolvimento (sem custos extras)
WHISPER_PROVIDER="local"
TTS_PROVIDER="native"

###########################################
######## CONFIGURA√á√ïES DE DESENVOLVIMENTO #
###########################################
# Otimiza√ß√µes para desenvolvimento
DISABLE_TELEMETRY="true"
COLLECTOR_ALLOW_ANY_IP="true"
PASSWORDMINCHAR=4
PASSWORDREQUIREMENTS=1
TARGET_OCR_LANG=eng,por
NODE_ENV=development

###########################################
######## ALTERNATIVAS DE LLM #############
###########################################
# Descomente para usar outros providers:

# ANTHROPIC (Boa qualidade, ~$15/m√™s uso moderado)
# LLM_PROVIDER='anthropic'
# ANTHROPIC_API_KEY=sk-ant-your-api-key-here
# ANTHROPIC_MODEL_PREF='claude-3-haiku-20240307'

# GROQ (Muito r√°pido e barato, ~$5/m√™s)
# LLM_PROVIDER='groq'
# GROQ_API_KEY=gsk_your-api-key-here
# GROQ_MODEL_PREF=llama3-8b-8192

# OPENROUTER (Acesso a m√∫ltiplos modelos)
# LLM_PROVIDER='openrouter'
# OPENROUTER_API_KEY=sk-or-your-api-key-here
# OPENROUTER_MODEL_PREF='anthropic/claude-3-haiku'

###########################################
######## NOTAS DE SETUP ##################
###########################################
# 1. Configure sua API key acima (OPEN_AI_KEY)
# 2. Execute: yarn dev:server && yarn dev:frontend && yarn dev:collector
# 3. Acesse: http://localhost:3000 (frontend) ou http://localhost:3001 (API)
#
# VANTAGENS:
# ‚úÖ Setup instant√¢neo (sem downloads pesados)
# ‚úÖ Zero overhead de CPU/RAM local
# ‚úÖ Mesma qualidade de LLM que produ√ß√£o
# ‚úÖ Desenvolvimento r√°pido e responsivo
# ‚úÖ Deploy sem atrito (mesmo provider)
#
# COMPATIBILIDADE:
# ‚úÖ 100% compat√≠vel com documenta√ß√£o oficial AnythingLLM
# ‚úÖ Segue todas as pr√°ticas recomendadas pela Mintplex Labs
# üìñ Docs oficiais: https://docs.anythingllm.com/llm-configuration